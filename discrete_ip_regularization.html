
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2. Discrete Inverse Problems and Regularization &#8212; 10 Lectures on Inverse Problems and Imaging</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Linear inverse problems in function spaces" href="ip_function_spaces.html" />
    <link rel="prev" title="1. What is an inverse problem" href="what_is.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">10 Lectures on Inverse Problems and Imaging</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to Inverse Problems and Imaging
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="what_is.html">
   1. What is an inverse problem
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   2. Discrete Inverse Problems and Regularization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ip_function_spaces.html">
   3. Linear inverse problems in function spaces
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="statistical_perspective.html">
   4. A statistical perspective on inverse problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="variational_formulations.html">
   5. Variational formulations for inverse problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="numerical_optimisation.html">
   6. Numerical optimization for inverse problems
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="image_processing.html">
   7. Image processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tomography.html">
   8. Computed Tomography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wavefield_imaging.html">
   9. Wavefield Imaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="magnetic_resonance_imaging.html">
   10. Magnetic Resonance Imaging
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   11. References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/discrete_ip_regularization.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/discrete_ip_regularization.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        
        <a class="edit-button" href="https://github.com/TristanvanLeeuwen/IP_and_Im_Lectures/edit/master/discrete_ip_regularization.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/TristanvanLeeuwen/IP_and_Im_Lectures/master?urlpath=tree/discrete_ip_regularization.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#well-posedness">
   2.1. Well-posedness
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pseudo-inverse">
   2.2. Pseudo inverse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation">
   2.3. Regularisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   2.4. Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     2.4.1. Pseudo-inverse
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#least-squares-and-minimum-norm-solutions">
     2.4.2. Least-squares and minimum-norm solutions:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tikhonov-regularization">
     2.4.3. Tikhonov regularization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gravity-surveying">
     2.4.4. Gravity surveying
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#assignments">
   2.5. Assignments
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolution">
     2.5.1. Convolution
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Discrete Inverse Problems and Regularization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#well-posedness">
   2.1. Well-posedness
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pseudo-inverse">
   2.2. Pseudo inverse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation">
   2.3. Regularisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   2.4. Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     2.4.1. Pseudo-inverse
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#least-squares-and-minimum-norm-solutions">
     2.4.2. Least-squares and minimum-norm solutions:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tikhonov-regularization">
     2.4.3. Tikhonov regularization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gravity-surveying">
     2.4.4. Gravity surveying
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#assignments">
   2.5. Assignments
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolution">
     2.5.1. Convolution
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="discrete-inverse-problems-and-regularization">
<h1><span class="section-number">2. </span>Discrete Inverse Problems and Regularization<a class="headerlink" href="#discrete-inverse-problems-and-regularization" title="Permalink to this headline">¶</a></h1>
<p>In this lecture we consider inverse problems that can be posed as a system of linear equations</p>
<div class="math notranslate nohighlight">
\[
Ku = f,
\]</div>
<p>with <span class="math notranslate nohighlight">\(K \in \mathbb{R}^{m\times n}\)</span> a given matrix and <span class="math notranslate nohighlight">\(f\in \mathbb{R}^{m}\)</span> the data. The goal is to find a solution <span class="math notranslate nohighlight">\(u \in \mathbb{R}^n\)</span> that (approximately) satisfies the equations.</p>
<div class="section" id="well-posedness">
<h2><span class="section-number">2.1. </span>Well-posedness<a class="headerlink" href="#well-posedness" title="Permalink to this headline">¶</a></h2>
<p>The first questions we address in detail are those of <em>existence</em>, <em>uniqueness</em> and <em>stability</em> of the solution. We discern the following cases:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(m = n\)</span> and <span class="math notranslate nohighlight">\(K\)</span> has full rank, it is invertible and the solution is given by</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\widetilde u = K^{-1}f.
\]</div>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(m &gt; n\)</span> and <span class="math notranslate nohighlight">\(K\)</span> has rank <span class="math notranslate nohighlight">\(n\)</span>, the system of equations may be <em>inconsistent</em> in which case a solution does not exist when <span class="math notranslate nohighlight">\(f\)</span> is not in the range of <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(m &lt; n\)</span> and <span class="math notranslate nohighlight">\(K\)</span> has rank <span class="math notranslate nohighlight">\(m\)</span>, we can always find a solution but it may not be unique because <span class="math notranslate nohighlight">\(K\)</span> has a non-trivial <em>null-space</em>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(K\)</span> does not have maximal rank, the system of equations may be both inconsistent and <span class="math notranslate nohighlight">\(K\)</span> can have a null-space.</p></li>
</ul>
<p>Stability in this context means that errors in the data do not get amplified too much. For now, we’ll only consider stability in case the solution exists and is unique. Consider the systems <span class="math notranslate nohighlight">\(K\widetilde{u} = f\)</span> and <span class="math notranslate nohighlight">\(K\widetilde{u}^{\delta} = f^{\delta}\)</span> for which we have</p>
<div class="math notranslate nohighlight">
\[
\|\widetilde u - \widetilde u^{\delta}\| = \|K^{-1}(f - f^{\delta})\| \leq \|K^{-1}\| \|f - f^{\delta}\|,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\|u\|\)</span> denotes any <a class="reference external" href="https://en.wikipedia.org/wiki/Real_coordinate_space#Norms_on_Rn">vector norm on <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span></a> and <span class="math notranslate nohighlight">\(\|K\|\)</span> denotes its corresponding (induced) <a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_norm#Matrix_norms_induced_by_vector_norms">matrix norm</a>.</p>
<p>Since <span class="math notranslate nohighlight">\(\|f\| = \|K\widetilde u\| \leq \|K\| \|\widetilde u\|\)</span>, we can express the <em>relative error</em> as</p>
<div class="math notranslate nohighlight">
\[
\frac{\|\widetilde u - \widetilde u^{\delta}\|}{\|\widetilde u\|} \leq  \|K\|\|K^{-1}\| \frac{\|f - f^{\delta}\|}{\|f\|}.
\]</div>
<p>The quantity <span class="math notranslate nohighlight">\(\kappa(K) = \|K\|\|K^{-1}\|\)</span> is called the <a class="reference external" href="https://en.wikipedia.org/wiki/Condition_number#Matrices"><em>condition number</em></a> of <span class="math notranslate nohighlight">\(K\)</span>.</p>
</div>
<div class="section" id="pseudo-inverse">
<h2><span class="section-number">2.2. </span>Pseudo inverse<a class="headerlink" href="#pseudo-inverse" title="Permalink to this headline">¶</a></h2>
<p>Next, we discuss how we may define solutions to inconsistent or underdetermined systems of equations. For this, we’ll use the <a class="reference external" href="https://en.wikipedia.org/wiki/Singular_value_decomposition">singular value decomposition</a> of the matrix <span class="math notranslate nohighlight">\(K\)</span>.</p>
<hr class="docutils" />
<p>If <span class="math notranslate nohighlight">\(m &gt; n\)</span>, the system is inconsistent when <span class="math notranslate nohighlight">\(f\)</span> is not in the range of <span class="math notranslate nohighlight">\(K\)</span>. If <span class="math notranslate nohighlight">\(K\)</span> has full rank we can express it as</p>
<div class="math notranslate nohighlight">
\[
K = U_n \Sigma_n V_n^*,
\]</div>
<p>with <span class="math notranslate nohighlight">\(U_n = (u_1, u_2, \ldots, u_n), V_n = (v_1, v_2, \ldots, v_n)\)</span> containing the first <span class="math notranslate nohighlight">\(n\)</span> left and right singular vectors and <span class="math notranslate nohighlight">\(\Sigma_n\)</span> is a diagonal matrix containing the singular values <span class="math notranslate nohighlight">\(\sigma_1 \geq \sigma_2 \geq \ldots \geq \sigma_{n} &gt; 0\)</span>. We can then attempt to solve a modified system of equations</p>
<div class="math notranslate nohighlight">
\[
K u =  U_nU_n^* f,
\]</div>
<p>where <span class="math notranslate nohighlight">\(U_nU_n^* f\)</span> projects <span class="math notranslate nohighlight">\(f\)</span> onto the range of <span class="math notranslate nohighlight">\(K\)</span>. We find</p>
<div class="math notranslate nohighlight">
\[
\widetilde u = V_n\Sigma_n^{-1}U_n^*f \equiv K^\dagger f,
\]</div>
<p>where <span class="math notranslate nohighlight">\(K^\dagger\)</span> denotes the <a class="reference external" href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">Moore-Penrose pseudo inverse</a> of <span class="math notranslate nohighlight">\(K\)</span>.</p>
<p>This coincides with the <em>least-squares</em> solution</p>
<div class="math notranslate nohighlight">
\[
\min_u \|Ku - f\|_2^2 .
\]</div>
<p>Indeed, by setting the gradient to zero, we find the normal equations</p>
<div class="math notranslate nohighlight">
\[
K^* K u  = K^* f,
\]</div>
<p>so</p>
<div class="math notranslate nohighlight">
\[
\widetilde u = (K^* K)^{-1}K^* f = K^{\dagger}f.
\]</div>
<div class="admonition-example-an-overdetermined-system-of-equations admonition">
<p class="admonition-title">Example: <em>An overdetermined system of equations</em></p>
<p>Consider solving</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left(
\begin{matrix}
1 &amp; 1 \\
2 &amp; 1 \\
1 &amp; 2 \\
\end{matrix}
\right)
\left(
\begin{matrix}
u_1 \\ u_2 \\
\end{matrix}
\right)
=
\left(
\begin{matrix}
1 \\ 1 \\ 1 \\
\end{matrix}
\right).
\end{split}\]</div>
<p>The system of equations is obviously not consistent. The corresponding normal equations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left(
\begin{matrix}
6 &amp; 5 \\
5 &amp; 6 \\
\end{matrix}
\right)
\left(
\begin{matrix}
u_1 \\ u_2 \\
\end{matrix}
\right)
=
\left(
\begin{matrix}
4 \\ 4 \\
\end{matrix}
\right)
\end{split}\]</div>
<p>do have a unique solution, <span class="math notranslate nohighlight">\(u = (4/11,4/11)^T\)</span>.</p>
</div>
<hr class="docutils" />
<p>If, on the other hand <span class="math notranslate nohighlight">\(m &lt; n\)</span> and <span class="math notranslate nohighlight">\(K\)</span> has full rank, a solution exists but is not unique. In this case, we can look for the <em>smallest</em> solution (i.e., one that does not have any contributions in the null-space of <span class="math notranslate nohighlight">\(K\)</span>).  This means we look for a solution that is spanned by the first <span class="math notranslate nohighlight">\(m\)</span> right singular vectors, denoted by <span class="math notranslate nohighlight">\(V_m = (v_1, v_2, \ldots v_m)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
K V_m z = f,
\]</div>
<p>with <span class="math notranslate nohighlight">\(\widetilde u = V_m z\)</span>. We find that this solution is given by</p>
<div class="math notranslate nohighlight">
\[
\widetilde{u} = V_m\Sigma_m^{-1}U_m^*f \equiv  K^{\dagger}f,
\]</div>
<p>where <span class="math notranslate nohighlight">\(U_m = (u_1, u_2, \ldots u_m)\)</span>, and <span class="math notranslate nohighlight">\(\Sigma_m\)</span> contains the non-zero singular values <span class="math notranslate nohighlight">\(\sigma_1 \geq \sigma_2, \ldots, \sigma_m &gt; 0\)</span>. Showing that this indeed yields the solution with the smallest norm is the subject of one of the assignments. The corresponding variational problem is</p>
<div class="math notranslate nohighlight">
\[
\min_{u} \|u\|_2^2 \quad \text{such that} \quad Ku = f.
\]</div>
<div class="admonition-example-an-underdetermined-system-of-equations admonition">
<p class="admonition-title">Example: <em>An underdetermined system of equations</em></p>
<p>Consider solving</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left(
\begin{matrix}
1 &amp; 1 \\
\end{matrix}
\right)
\left(
\begin{matrix}
u_1 \\ u_2
\end{matrix}
\right)
=
\left(
\begin{matrix}
1 \\
\end{matrix}
\right).
\end{split}\]</div>
<p>The corresponding normal equations are given by <span class="math notranslate nohighlight">\(2v = 1\)</span>, and gives the solution <span class="math notranslate nohighlight">\(u = v (1,1)^T\)</span>. In effect this means that we have added an equation to the system: <span class="math notranslate nohighlight">\(u_1 - u_2 = 0\)</span>.</p>
</div>
<hr class="docutils" />
<p>If the matrix does not have full rank we may still employ the pseudo-inverse, which for a matrix of rank <span class="math notranslate nohighlight">\(k \leq \min\{m,n\}\)</span> is defined as follows.</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Moore-Penrose pseudo inverse</em></p>
<p>The pseudo-inverse of a matrix <span class="math notranslate nohighlight">\(K \in \mathbb{R}^{m,n}\)</span> with rank <span class="math notranslate nohighlight">\(k \leq \min\{m,n\}\)</span> is defined in terms of the singular value decomposition as</p>
<div class="math notranslate nohighlight">
\[
K^{\dagger} = V_k\Sigma_k^{-1}U_k^{*},
\]</div>
<p>where <span class="math notranslate nohighlight">\(V_k = (v_1, v_2, \ldots, v_k)\)</span>, <span class="math notranslate nohighlight">\(U_k = (u_1, u_2, \ldots, u_k)\)</span> and <span class="math notranslate nohighlight">\(\Sigma_k\)</span> contains the <span class="math notranslate nohighlight">\(k\)</span> largest singular values.</p>
</div>
<hr class="docutils" />
<p>Note that the pseudo inverse allows us to define a unique solution, it is not necessarily stable as <span class="math notranslate nohighlight">\(\|K\|_2\|K^{\dagger}\|_2 = \sigma_1/\sigma_k\)</span> may still be large. To study this issue in more detail, express the solution as</p>
<div class="math notranslate nohighlight">
\[
\widetilde{u} = V_k\Sigma_k^{-1}U_k^{*}f = \sum_{i=1}^k \frac{\langle u_i, f\rangle}{\sigma_i}v_i.
\]</div>
<p>We note the component in <span class="math notranslate nohighlight">\(f\)</span> corresponding to <span class="math notranslate nohighlight">\(v_i\)</span> is amplified by <span class="math notranslate nohighlight">\(\sigma_i^{-1}\)</span>. Thus if <span class="math notranslate nohighlight">\(f\)</span> has (noise) components that correlate with <span class="math notranslate nohighlight">\(v_i\)</span>’s corresponding to very small singular values, these noise components get amplified. Generally, we do not expect problems if <span class="math notranslate nohighlight">\(|\langle u_i, f\rangle|\)</span> decays faster with <span class="math notranslate nohighlight">\(i\)</span> than the singular values <span class="math notranslate nohighlight">\(\sigma_i\)</span>. This is called the <em>discrete Picard condition</em> <span id="id1">[<a class="reference internal" href="bibliography.html#id3" title="Per Christian Hansen. The discrete picard condition for discrete ill-posed problems. BIT Numerical Mathematics, 30(4):658–672, 1990.">Hansen, 1990</a>]</span>.</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Discrete Picard Condition</em></p>
<p>The vector <span class="math notranslate nohighlight">\(f \in \mathbb{R}^m\)</span> satisfies the discrete Picard condition for the problem <span class="math notranslate nohighlight">\(Ku=f\)</span> if the coefficients <span class="math notranslate nohighlight">\(|\langle u_i, f\rangle|\)</span> decay faster than the singular values <span class="math notranslate nohighlight">\(\sigma_i\)</span> of <span class="math notranslate nohighlight">\(K\)</span>, where <span class="math notranslate nohighlight">\(u_i\)</span> denotes the left singular vectors of <span class="math notranslate nohighlight">\(K\)</span>.</p>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="c1"># define forward operator</span>
<span class="k">def</span> <span class="nf">getK</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="o">*</span><span class="n">x</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">K</span><span class="p">,</span><span class="n">x</span>

<span class="c1"># parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">K</span><span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="n">getK</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># define ground truth and compute data</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">K</span><span class="nd">@u</span>

<span class="c1"># add noise</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">f_delta</span> <span class="o">=</span> <span class="n">f</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">noise</span>

<span class="c1"># SVD</span>
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># apply pseudo inverse</span>
<span class="n">uhat</span> <span class="o">=</span> <span class="n">Vh</span><span class="o">.</span><span class="n">T</span><span class="nd">@np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">s</span><span class="p">)</span><span class="nd">@U</span><span class="o">.</span><span class="n">T</span><span class="nd">@f_delta</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="s1">&#39;*&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\sigma_i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="nd">@f</span><span class="p">),</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$|\langle u_i, f\rangle|$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="nd">@f_delta</span><span class="p">),</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$|\langle u_i, f^{\delta}\rangle|$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="nd">@f</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span><span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mf">1e-6</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;picard&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_1_1.png" src="_images/discrete_ip_regularization_1_1.png" />
</div>
</div>
<div class="admonition-example-an-ill-posed-problem admonition">
<p class="admonition-title">Example <em>An ill-posed problem</em></p>
<p>As forward operator we take a diagonal matrix with entries</p>
<div class="math notranslate nohighlight">
\[(K)_{ii} = \exp(-5 \cdot i/(n-1))\quad \text{for}\quad i = 0, 2, \ldots, n-1.\]</div>
<p>We generate noisy data <span class="math notranslate nohighlight">\(f^\delta = K \overline{u} + e\)</span> with <span class="math notranslate nohighlight">\(\overline{u}_i = \exp(-10 \cdot i/(n-1))\)</span> and <span class="math notranslate nohighlight">\(e_i\)</span> normally distributed with mean zero and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. We then find that</p>
<div class="math notranslate nohighlight">
\[|\langle u_i, f\rangle| = |f_i| = \exp(-15 \cdot i/(n-1)),\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[|\langle u_i, f^\delta\rangle| = |\exp(-15 \cdot i/(n-1)) + e_i| \leq |\langle u_i, f\rangle| + |e_i|.\]</div>
<p>Since <span class="math notranslate nohighlight">\(e_i\)</span> is normally distributed, its absolute value follows a <a class="reference external" href="https://en.wikipedia.org/wiki/Folded_normal_distribution">folded normal distribution</a>. This allows us to compute the expected upper bound</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}(|e_i|) = \sqrt{\frac{2}{\pi}}\sigma.\]</div>
<p>We conclude that <span class="math notranslate nohighlight">\(|\langle u_i, f^\delta\rangle|\)</span> does not decay exponentially as the singular values do and hence do not satisfy the discrete Picard condition.</p>
<div class="figure align-default" id="picard" style="width: 600px">
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_1_0.png" src="_images/discrete_ip_regularization_1_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 2.1 </span><span class="caption-text">An example of the singular values and the coefficients <span class="math notranslate nohighlight">\(|\langle u_i, f\rangle|\)</span> and <span class="math notranslate nohighlight">\(|\langle u_i, f^\delta\rangle|\)</span> for <span class="math notranslate nohighlight">\(n = 100\)</span> and <span class="math notranslate nohighlight">\(\sigma = 10^{-2}\)</span>. We see that <span class="math notranslate nohighlight">\(f\)</span> does satisfy the discrete Picard condition while <span class="math notranslate nohighlight">\(f^\delta\)</span> does not.</span><a class="headerlink" href="#picard" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="regularisation">
<h2><span class="section-number">2.3. </span>Regularisation<a class="headerlink" href="#regularisation" title="Permalink to this headline">¶</a></h2>
<p>To stabilize the problem we can modify the pseudo inverse in several ways to avoid dividing by small singular values. One option is to simply ignore small singular values and choose a cut-off value and define the solution as</p>
<div class="math notranslate nohighlight" id="equation-regk">
<span class="eqno">(2.1)<a class="headerlink" href="#equation-regk" title="Permalink to this equation">¶</a></span>\[\widetilde u_{\alpha} = V_{k}r_{\alpha}(\Sigma_{k}){U_{k}}^*f,\]</div>
<p>where <span class="math notranslate nohighlight">\(r_{\alpha}\)</span> is applied component-wise to the diagonal of the matrix <span class="math notranslate nohighlight">\(\Sigma_k\)</span> as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
r_{\alpha}(\sigma) =
\left\{
\begin{array}{ccc}
\sigma^{-1} &amp; \text{if} \quad \sigma \geq \alpha \\
0 &amp; \text{otherwise} \\
\end{array}
\right.
\end{split}\]</div>
<p>This gives rise to the Truncated Singular Value Decomposition (TSVD).</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Truncated Singular Value Decomposition (TSVD)</em></p>
<p>The TSVD-regularized solution to the equation <span class="math notranslate nohighlight">\(Ku = f\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\widetilde u_{\alpha} = \sum_{i=1}^{k_{\alpha}} \frac{\langle u_i, f\rangle}{\sigma_i}v_i,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\{(u_i,v_i,\sigma_i)\}_{i=1}^k\)</span> denotes the singular system of <span class="math notranslate nohighlight">\(K\)</span> and <span class="math notranslate nohighlight">\(k_{\alpha} \leq k\)</span> is chosen so that <span class="math notranslate nohighlight">\(\sigma_i \geq \alpha\)</span> for <span class="math notranslate nohighlight">\(i \leq k_{\alpha}\)</span>.</p>
</div>
<hr class="docutils" />
<p>Another option to avoid dividing by small singular values is to add small positive constant to shift the singular values away from zero. This gives rise to Tikhonov regularization.</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Tikhonov regularisation</em></p>
<p>The Tikhonov-regularised solution to the equation <span class="math notranslate nohighlight">\(Ku = f\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\widetilde u_{\alpha} = \sum_{i=1}^{k} \frac{\sigma_i \langle u_i, f\rangle}{\sigma_i^2 + \alpha}v_i,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\{(u_i,v_i,\sigma_i)\}_{i=1}^k\)</span> is the singular system of <span class="math notranslate nohighlight">\(K\)</span>. This corresponds to setting <span class="math notranslate nohighlight">\(r_{\alpha}(s) = s/(s^2 + \alpha)\)</span> in <a class="reference internal" href="#equation-regk">(2.1)</a>.</p>
<p>Unlike the TSVD, Tikhonov regularisation has a corresponding variational problem:</p>
<div class="math notranslate nohighlight">
\[
\min_u \|Ku - f\|_2^2 + \alpha \|u\|_2^2,
\]</div>
<p>whose well-posedness can be easily established by writing down the corresponding normal equations</p>
<div class="math notranslate nohighlight">
\[
\widetilde{u}_{\alpha} = \left(K^* K + \alpha I\right)^{-1}K^* f = V_k\left(\Sigma_k^2 + \alpha I\right)^{-1}\Sigma_k {U_k}^*f.
\]</div>
<p>Indeed, it is easily verified that <span class="math notranslate nohighlight">\(K^* K + \alpha I\)</span> has full rank whenever <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span>.</p>
</div>
<hr class="docutils" />
<p>Of course, one may think of other types of regularization by defining an appropriate function <span class="math notranslate nohighlight">\(r_{\alpha}\)</span>. Intuitively, we would like</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r_{\alpha}(s) = s^{-1}\)</span> as <span class="math notranslate nohighlight">\(\alpha \rightarrow 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(r_{\alpha}(0) &lt; \infty\)</span> for any <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(r_{\alpha}(s) \rightarrow 0\)</span> as <span class="math notranslate nohighlight">\(\alpha \rightarrow \infty\)</span></p></li>
</ul>
<p>One example is <em>Lavrentiev</em> regularization, with:</p>
<div class="math notranslate nohighlight">
\[r_{\alpha}(s) = (s + \alpha)^{-1}.\]</div>
<p>Conditions on regularization schemes and methods for choosing <span class="math notranslate nohighlight">\(\alpha\)</span> will be discussed in more detail in the chapter on <a class="reference internal" href="ip_function_spaces.html"><span class="doc std std-doc">Inverse Problems in Function Spaces</span></a>.</p>
<hr class="docutils" />
<p>In general, we can think of regularization for linear problems as defining a modified pseudo-inverse of <span class="math notranslate nohighlight">\(K\)</span>:</p>
<div class="math notranslate nohighlight">
\[K_{\alpha}^{\dagger} = V_{k}r_{\alpha}(\Sigma_{k})U_{k}^{*}.\]</div>
<p>Stability of regularized solutions defined by <a class="reference internal" href="#equation-regk">(2.1)</a> then follows by considering the largest singular value of <span class="math notranslate nohighlight">\(K_{\alpha}^\dagger\)</span>, which can be made arbitrarily small by increasing <span class="math notranslate nohighlight">\(\alpha\)</span>. On the other hand, increasing <span class="math notranslate nohighlight">\(\alpha\)</span> will also introduce a bias in the solution. This trade-off is called the <em>bias-variance trade-off</em>:</p>
<div class="important admonition">
<p class="admonition-title">Definition: <em>Bias-variance trade-off</em></p>
<p>Here, we compare the regularised solution from noisy data <span class="math notranslate nohighlight">\(\widetilde{u}_{\alpha, \delta} = K_{\alpha}^\dagger f^{\delta}\)</span> and the ideal solution <span class="math notranslate nohighlight">\(\widetilde{u} = K^{\dagger}f\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\|\widetilde u - \widetilde u_{\alpha, \delta}\| \leq \underbrace{\|(K^\dagger - K_{\alpha}^\dagger)f\|}_{\text{bias}} + \underbrace{\|K_{\alpha}^\dagger(f - f^{\delta})\|}_{\text{variance}}.
\]</div>
<p>If <span class="math notranslate nohighlight">\(\alpha \downarrow 0\)</span>, the bias goes to zero, but possibly leads to a large variance. Large <span class="math notranslate nohighlight">\(\alpha\)</span> on the other hand reduces the variance but leads to a large bias. Ideally, the regularisation parameter is chosen in such a way that the small singular values are stabilised and the large ones are hardly effected.</p>
<p>We can make a similar decomposition of the error between the ground truth <span class="math notranslate nohighlight">\(\overline{u}\)</span> and the regularised solution</p>
<div class="math notranslate nohighlight">
\[\|\overline{u} - \widetilde{u}_{\alpha,\delta}\| \leq \|\overline{u} - K_{\alpha}^\dagger f\| + \|K_{\alpha}^\dagger(f - f^\delta)\|.\]</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="c1"># define forward operator</span>
<span class="k">def</span> <span class="nf">getK</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="o">*</span><span class="n">x</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">K</span><span class="p">,</span><span class="n">x</span>

<span class="c1"># parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">K</span><span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="n">getK</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># define ground truth and compute data</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">K</span><span class="nd">@u</span>

<span class="c1"># add noise</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">f_delta</span> <span class="o">=</span> <span class="n">f</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">noise</span>

<span class="c1"># SVD</span>
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># error, bias and variance for TSVD</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
  <span class="n">uk</span> <span class="o">=</span> <span class="n">Vh</span><span class="p">[:</span><span class="n">k</span><span class="p">,:]</span><span class="o">.</span><span class="n">T</span><span class="nd">@np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">s</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span><span class="nd">@U</span><span class="p">[:,:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="nd">@f</span>
  <span class="n">uk_delta</span> <span class="o">=</span> <span class="n">Vh</span><span class="p">[:</span><span class="n">k</span><span class="p">,:]</span><span class="o">.</span><span class="n">T</span><span class="nd">@np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">s</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span><span class="nd">@U</span><span class="p">[:,:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="nd">@f_delta</span>

  <span class="n">error</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">uk_delta</span><span class="p">)</span>
  <span class="n">bias</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">uk</span><span class="p">)</span>
  <span class="n">variance</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">uk</span> <span class="o">-</span> <span class="n">uk_delta</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;bias&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">variance</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">k</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="s1">&#39;k--&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$k$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;error&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;bias_variance&quot;</span><span class="p">,</span><span class="n">fig</span><span class="p">,</span><span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_3_1.png" src="_images/discrete_ip_regularization_3_1.png" />
</div>
</div>
<div class="admonition-example-an-ill-posed-problem-cont-d admonition">
<p class="admonition-title">Example <em>An ill-posed problem, cont’d</em></p>
<p>Using the same forward operator and ground truth as the previous example and use TSVD-regularisation to regularise the problem. Using the truncation rank, <span class="math notranslate nohighlight">\(k\)</span>, as the regularisation parameter we find that</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left(K_{k}^\dagger f^\delta \right)_i = \begin{cases} \overline{u}_i + \exp(5\cdot i /(n-1))e_i &amp; i\leq k \\ 0 &amp; i &gt; k\end{cases}.\end{split}\]</div>
<p>Thus, the error becomes</p>
<div class="math notranslate nohighlight">
\[\|\overline{u} - K_k^\dagger f^{\delta}\|_2^2 = \sum_{i=0}^k e^{10i /(n-1)}e_i^2 + \sum_{i=k+1}^{n-1} e^{-20i /(n-1)},
\]</div>
<p>in which we recognise the bias and variance terms. In expectation, the upper bound for the error is then given by <span class="math notranslate nohighlight">\((k+1)e^{5k/(n-1)}\sigma + (n-k-1)e^{-10(k+1)/(n-1)}\)</span>. While not very tight, it does suggest that there is an optimal <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="figure align-default" id="bias-variance" style="width: 600px">
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_3_0.png" src="_images/discrete_ip_regularization_3_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 2.2 </span><span class="caption-text">An example of the error <span class="math notranslate nohighlight">\(\|\overline{u} - K_{\alpha}^\dagger f^\delta\|_2\)</span> and corresponding bias and variance for <span class="math notranslate nohighlight">\(n = 100\)</span> and <span class="math notranslate nohighlight">\(\sigma = 10^{-2}\)</span>. As predicted, the bias decreases with <span class="math notranslate nohighlight">\(k\)</span> while the variance increases. The optimal <span class="math notranslate nohighlight">\(k\)</span> for this noise level lies at <span class="math notranslate nohighlight">\(k \approx 30\)</span>. Look at <a class="reference internal" href="#picard"><span class="std std-numref">Fig. 2.1</span></a>, do you see why this is the optimal <span class="math notranslate nohighlight">\(k\)</span>?</span><a class="headerlink" href="#bias-variance" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="exercises">
<h2><span class="section-number">2.4. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3><span class="section-number">2.4.1. </span>Pseudo-inverse<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Show that for a given matrix <span class="math notranslate nohighlight">\(K \in \mathbb{R}^{m\times n}\)</span>:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(KK^\dagger\)</span> is an orthogonal projection on to the range of <span class="math notranslate nohighlight">\(K\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(I - K^\dagger K\)</span> is an orthogonal projection to to the null-space of <span class="math notranslate nohighlight">\(K\)</span></p></li>
</ol>
<div class="hint dropdown admonition">
<p class="admonition-title">Answer</p>
<ol class="simple">
<li><p>Express the pseudo-inverse in terms of the SVD as <span class="math notranslate nohighlight">\(K^\dagger = V_k\Sigma_k^{-1}U_k^*\)</span> and find <span class="math notranslate nohighlight">\(KK^\dagger = U_kU_k^*\)</span>. Because <span class="math notranslate nohighlight">\(U_k = (u_1, u_2, \ldots, u_k)\)</span> is an orthonormal basis for the range of <span class="math notranslate nohighlight">\(K\)</span> we find that <span class="math notranslate nohighlight">\(KK^\dagger\)</span> is an orthogonal project on to the range of <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
<li><p>Following a similar argument we find that <span class="math notranslate nohighlight">\(K^\dagger K = V_kV_k^*\)</span> where <span class="math notranslate nohighlight">\(V_k = (v_1, v_2, \ldots, v_k)\)</span> spans the orthogonal complement of the null-space of <span class="math notranslate nohighlight">\(K\)</span> (recall that the null-space of <span class="math notranslate nohighlight">\(K\)</span> is spanned by <span class="math notranslate nohighlight">\((v_{k+1},
\ldots, v_{\min_{m,n}})\)</span>).</p></li>
</ol>
</div>
</div>
<div class="section" id="least-squares-and-minimum-norm-solutions">
<h3><span class="section-number">2.4.2. </span>Least-squares and minimum-norm solutions:<a class="headerlink" href="#least-squares-and-minimum-norm-solutions" title="Permalink to this headline">¶</a></h3>
<p>Given a system of equations <span class="math notranslate nohighlight">\(Ku = f\)</span> with <span class="math notranslate nohighlight">\(K\in\mathbb{R}^{m\times n}\)</span>:</p>
<ol class="simple">
<li><p>For <span class="math notranslate nohighlight">\(m &gt; n\)</span> and rank(<span class="math notranslate nohighlight">\(K\)</span>) = <span class="math notranslate nohighlight">\(n\)</span>, show that the pseudo-inverse gives the solution <span class="math notranslate nohighlight">\(u = K^\dagger f\)</span> with the smallest residual <span class="math notranslate nohighlight">\(\|Ku - f\|_2\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(m &lt; n\)</span> and rank(<span class="math notranslate nohighlight">\(K\)</span>) = <span class="math notranslate nohighlight">\(m\)</span>, show that the pseudo-inverse gives the solution <span class="math notranslate nohighlight">\(u = K^\dagger f\)</span> with the smallest norm <span class="math notranslate nohighlight">\(\|u\|_2\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(m &gt; n\)</span> and rank(<span class="math notranslate nohighlight">\(K\)</span>) = <span class="math notranslate nohighlight">\(r &lt; n\)</span>, show that the pseudo-inverse gives the solution that minimizes both <span class="math notranslate nohighlight">\(\|Ku - f\|_2\)</span> and <span class="math notranslate nohighlight">\(\|u\|_2\)</span>.</p></li>
</ol>
<div class="hint dropdown admonition">
<p class="admonition-title">Answer</p>
<ol class="simple">
<li><p>We can construct the solution with the smallest residual by formulating the corresponding normal equations <span class="math notranslate nohighlight">\(K^*Ku = K^*f\)</span>. Since rank(<span class="math notranslate nohighlight">\(K\)</span>) = <span class="math notranslate nohighlight">\(n\)</span>, these have a unique solution. Expressing <span class="math notranslate nohighlight">\(K\)</span> and <span class="math notranslate nohighlight">\(K^\dagger\)</span> in terms of the SVD of <span class="math notranslate nohighlight">\(K\)</span> we find that <span class="math notranslate nohighlight">\(K^\dagger = (K^*K)^{-1}K^*\)</span> and hence that pseudo-inverse yields the solution to the normal equations.</p></li>
<li><p>Here, the system solutions of the form <span class="math notranslate nohighlight">\(v = u + z\)</span> with <span class="math notranslate nohighlight">\(u = K^\dagger f\)</span> and <span class="math notranslate nohighlight">\(Kz = 0\)</span>. We find that <span class="math notranslate nohighlight">\(\|v\|_2^2 = \|u\|_2^2 + 2 \langle z, K^{\dagger} f \rangle + \|z\|_2^2\)</span>. Expressing in terms of the SVD we see that the middle term is given by <span class="math notranslate nohighlight">\(\langle z, V_k\Sigma_k^{-1}U_k^*f\rangle\)</span>. Since <span class="math notranslate nohighlight">\(z\)</span> lies in the null-space of <span class="math notranslate nohighlight">\(K\)</span> we <span class="math notranslate nohighlight">\(V_k^*z = 0\)</span> so <span class="math notranslate nohighlight">\(\|v\|_2^2= \|u\|_2^2 + \|z\|_2^2 \geq \|u\|_2^2\)</span>. We conclude that <span class="math notranslate nohighlight">\(\|u\|_2^2\)</span> is indeed the solution with the smallest norm.</p></li>
<li><p>We can combine the results of the former to to show that in this case <span class="math notranslate nohighlight">\(u = K^\dagger f\)</span> is <em>a</em> solution to the normal equations and that it is the one with the smallest norm.</p></li>
</ol>
</div>
</div>
<div class="section" id="tikhonov-regularization">
<h3><span class="section-number">2.4.3. </span>Tikhonov regularization<a class="headerlink" href="#tikhonov-regularization" title="Permalink to this headline">¶</a></h3>
<p>Show that the solution to the variational problem</p>
<div class="math notranslate nohighlight">
\[\min_{u} \|Ku - f\|_2^2 + \alpha \|u\|_2^2\]</div>
<p>is given in terms of the SVD of <span class="math notranslate nohighlight">\(K \in \mathbb{R}^{m\times n}\)</span> as</p>
<div class="math notranslate nohighlight">
\[\widetilde{u} = \sum_{i=1}^{k} \frac{\sigma_i \langle u_i, f\rangle}{\sigma_i^2 + \alpha} v_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(k = \text{rank}(K)\)</span>.</p>
<div class="hint dropdown admonition">
<p class="admonition-title">Answer</p>
<p>First, write down the corresponding normal equations <span class="math notranslate nohighlight">\(K^*Ku + \alpha u = K^*f\)</span>, so <span class="math notranslate nohighlight">\(u = (K^*K + \alpha I)^{-1}K^*f\)</span>. Use the <em>full</em> SVD of <span class="math notranslate nohighlight">\(K = U\Sigma V^*\)</span> with <span class="math notranslate nohighlight">\(U\in\mathbb{R}^{m\times m}\)</span>, <span class="math notranslate nohighlight">\(V\in\mathbb{R}^{n\times n}\)</span> and <span class="math notranslate nohighlight">\(\Sigma \in \mathbb{R}^{m\times n}\)</span> whose first <span class="math notranslate nohighlight">\(k\)</span> diagonal entries contain the singular values. We find <span class="math notranslate nohighlight">\(u = (V^*\Sigma^*\Sigma V + \alpha I)^{-1}V\Sigma^*U^*\)</span>. Use that <span class="math notranslate nohighlight">\(V^*V = VV^* = I\)</span> and <span class="math notranslate nohighlight">\(\Sigma_n^2 = \Sigma^*\Sigma\)</span> an <span class="math notranslate nohighlight">\(n \times n\)</span> matrix with <span class="math notranslate nohighlight">\(k\)</span> non-zero diagonal elements. Then the normal equations become <span class="math notranslate nohighlight">\(u = V(\Sigma_n^2 + \alpha I)^{-1}\Sigma^*U^*f\)</span>. We realise that <span class="math notranslate nohighlight">\(\Sigma^*U^*f\)</span> will only contain contributions from the <span class="math notranslate nohighlight">\(k\)</span> non-zero singular values: <span class="math notranslate nohighlight">\(\Sigma^*U^*f = (\sigma_1 u_1^*f,\sigma_2 u_2^*f, \ldots, \sigma_k \langle u_k, f\rangle, 0, 0, \ldots, 0 )\)</span>. Thus, we get the desired result.</p>
</div>
</div>
<div class="section" id="gravity-surveying">
<h3><span class="section-number">2.4.4. </span>Gravity surveying<a class="headerlink" href="#gravity-surveying" title="Permalink to this headline">¶</a></h3>
<p>We can estimate the density distribution in the subsurface by measuring the local gravitational pull. The density profile <span class="math notranslate nohighlight">\(u(x)\)</span> is related to such measurements by a linear operator</p>
<div class="math notranslate nohighlight">
\[Ku(x) = \int_0^1 \frac{u(y)}{(1 + (x-y)^2)^{3/2}} \mathrm{d}y.\]</div>
<p>Upon discretization with stepsize <span class="math notranslate nohighlight">\(h = 1/n\)</span>, the inverse problem can be cast as a system of <span class="math notranslate nohighlight">\(n\)</span> equations in <span class="math notranslate nohighlight">\(n\)</span> unknowns <span class="math notranslate nohighlight">\(Ku = f\)</span>.</p>
<p>You can use the code provided below to generate the matrix and noisy data for a given <span class="math notranslate nohighlight">\(u(x)\)</span></p>
<ol class="simple">
<li><p>Plot the coefficients <span class="math notranslate nohighlight">\(\langle u_i, f\rangle\)</span> and the singular values <span class="math notranslate nohighlight">\(\sigma_i\)</span> to check the discrete Picard condition. What do you notice ?</p></li>
<li><p>Solve the inverse problem for noisy data using the (regularized) pseudo-inverse; compute the optimal <span class="math notranslate nohighlight">\(\alpha\)</span> by computing the bias and variance components of the error. Is this a practically feasible way to compute the optimal <span class="math notranslate nohighlight">\(\alpha\)</span>?</p></li>
<li><p>Compare the solutions for <span class="math notranslate nohighlight">\(\alpha &lt; \alpha_{\text{opt}}\)</span>, <span class="math notranslate nohighlight">\(\alpha_{\text{opt}}\)</span> and <span class="math notranslate nohighlight">\(\alpha &gt; \alpha_{\text{opt}}\)</span> to the ground truth. What do you notice?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">getK</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
    <span class="n">xx</span><span class="p">,</span><span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">xx</span> <span class="o">-</span> <span class="n">yy</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">K</span><span class="p">,</span><span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>

<span class="c1"># define forward operator</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">K</span><span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="n">getK</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># define ground truth and compute data</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">K</span><span class="nd">@u</span>

<span class="c1"># add noise</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">f_delta</span> <span class="o">=</span> <span class="n">f</span> <span class="o">+</span> <span class="n">delta</span><span class="o">*</span><span class="n">noise</span>

<span class="c1"># plot ground truth and data</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;u(x)&#39;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;clean data&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">f_delta</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;noisy data&#39;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_8_0.png" src="_images/discrete_ip_regularization_8_0.png" />
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>

<span class="c1"># define forward operator</span>
<span class="k">def</span> <span class="nf">getK</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
  <span class="n">h</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="n">xx</span><span class="p">,</span><span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
  <span class="n">K</span> <span class="o">=</span> <span class="n">h</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">xx</span> <span class="o">-</span> <span class="n">yy</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">K</span><span class="p">,</span><span class="n">x</span>

<span class="c1"># parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">K</span><span class="p">,</span><span class="n">x</span> <span class="o">=</span> <span class="n">getK</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># define ground truth and compute data</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">K</span><span class="nd">@u</span>

<span class="c1"># add noise</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">f_delta</span> <span class="o">=</span> <span class="n">f</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">noise</span>

<span class="c1"># SVD</span>
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># regularised pseudo inverse using Tikhonov</span>
<span class="n">R_alpha</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">alpha</span> <span class="p">:</span> <span class="n">Vh</span><span class="o">.</span><span class="n">T</span><span class="nd">@np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="o">/</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">))</span><span class="nd">@U</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># error, bias and variance for Tikhonov</span>
<span class="n">na</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">2e-5</span><span class="p">,</span><span class="n">na</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">na</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">na</span><span class="p">)</span>
<span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">na</span><span class="p">)</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">na</span><span class="p">):</span>
    <span class="n">error</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">R_alpha</span><span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="nd">@f_delta</span><span class="p">)</span>
    <span class="n">bias</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">u</span> <span class="o">-</span> <span class="n">R_alpha</span><span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="nd">@f</span><span class="p">)</span>
    <span class="n">variance</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">R_alpha</span><span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">@</span><span class="p">(</span><span class="n">f</span><span class="o">-</span><span class="n">f_delta</span><span class="p">))</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="s1">&#39;*&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\sigma_i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="nd">@f</span><span class="p">),</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$|\langle u_i, f\rangle|$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="nd">@f_delta</span><span class="p">),</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$|\langle u_i, f^\delta\rangle|$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;magnitude&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mf">1e-16</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">error</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;total error&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;bias&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">variance</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;variance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\alpha \cdot 10^</span><span class="si">{5}</span><span class="s1">$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;error&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mf">5e-6</span><span class="p">,</span><span class="mf">1e-5</span><span class="p">,</span><span class="mf">1.5e-5</span><span class="p">,</span><span class="mf">2e-5</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s1">&#39;.5&#39;</span><span class="p">,</span><span class="s1">&#39;1.0&#39;</span><span class="p">,</span><span class="s1">&#39;1.5&#39;</span><span class="p">,</span><span class="s1">&#39;2.0&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;ground truth&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">R_alpha</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span><span class="nd">@f_delta</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\alpha = 10^{-6}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">R_alpha</span><span class="p">(</span><span class="mf">1.5e-5</span><span class="p">)</span><span class="nd">@f_delta</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\alpha = 1.5\cdot 10^{-5}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">R_alpha</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">)</span><span class="nd">@f_delta</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\alpha = 10^{-4}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$u(x)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_9_0.png" src="_images/discrete_ip_regularization_9_0.png" />
</div>
</div>
<div class="hint dropdown admonition">
<p class="admonition-title">Answer</p>
<ol class="simple">
<li><p>In the first figure we see that the Fourier coefficients of the noisy data definitely do not obey the discrete Picard condition. The Fourier coefficients of <span class="math notranslate nohighlight">\(f\)</span> may even be problematic as they are on the same level as the singular values for <span class="math notranslate nohighlight">\(k &gt; 20\)</span>. This has to do with the numerical rank of <span class="math notranslate nohighlight">\(K\)</span>, which is roughly 20.</p></li>
<li><p>In the second figure we see the bias and variance parts of the error, the optimal <span class="math notranslate nohighlight">\(\alpha\)</span> (where they are equal) is approximately <span class="math notranslate nohighlight">\(1.5\cdot 10^{-5}\)</span>. We cannot compute the optimal <span class="math notranslate nohighlight">\(\alpha\)</span> in this way in practice since we do not have access to the ground truth nor the noise-free data needed to compute the terms. You may also want to vary the random seed to explore the influence of the particular random instance of the noise. This further indicates how difficult it would be to choose an optimal value for <span class="math notranslate nohighlight">\(\alpha\)</span> based only on knowledge of the <em>statistics</em> of the noise.</p></li>
<li><p>Comparing the solutions we note that for smaller <span class="math notranslate nohighlight">\(\alpha\)</span> we get more oscillations in the solutions while for larger <span class="math notranslate nohighlight">\(\alpha\)</span> we get smoother solutions. Remarkably we get a really good reconstruction for <span class="math notranslate nohighlight">\(\alpha = 1.5\cdot 10^{-5}\)</span>. This does not always have to be the case as you can explore in the assignment below.</p></li>
</ol>
</div>
</div>
</div>
<div class="section" id="assignments">
<h2><span class="section-number">2.5. </span>Assignments<a class="headerlink" href="#assignments" title="Permalink to this headline">¶</a></h2>
<div class="section" id="convolution">
<h3><span class="section-number">2.5.1. </span>Convolution<a class="headerlink" href="#convolution" title="Permalink to this headline">¶</a></h3>
<p>We are going to solve a deconvolution problem <span class="math notranslate nohighlight">\(Ku = f\)</span>, where <span class="math notranslate nohighlight">\(K\)</span> is a <em>Toeplitz matrix</em> with elements</p>
<div class="math notranslate nohighlight">
\[k_{ij} = \frac{\exp({-a\cdot (i-j)^2})}{(n-1)\sqrt{\pi/a}},\]</div>
<p>and we are given noisy measurements</p>
<div class="math notranslate nohighlight">
\[f^{\delta} = Ku + e,\]</div>
<p>where the entries of <span class="math notranslate nohighlight">\(e\)</span> are normally distributed with mean zero and variance <span class="math notranslate nohighlight">\(\delta^2\)</span>.</p>
<p>The goal of this assignment is to solve this inverse problem using a (truncated) SVD for two scenario’s</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(u(x) = H(x - 0.3) - H(x - 0.7)\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(u(x) = x(1-x)\)</span>,</p></li>
</ol>
<p>where <span class="math notranslate nohighlight">\(H\)</span> denotes the Heaviside step function.</p>
<p>For each of the two scenarios answer the following questions:</p>
<ol class="simple">
<li><p>Is this problem ill-posed?</p></li>
<li><p>Compute the (pseudo-)inverse of <span class="math notranslate nohighlight">\(K\)</span> using the SVD and compute the backward error <span class="math notranslate nohighlight">\(\|u - u^{\delta}\|_2\)</span> for noise levels <span class="math notranslate nohighlight">\(\delta = 0.001, 0.01, 0.1\)</span> for both scenario’s; what do you notice?</p></li>
<li><p>Compute a regularized solution using a truncated SVD for noise levels <span class="math notranslate nohighlight">\(\delta = 0.001, 0.01, 0.1\)</span> for both scenario’s. Manually choose the truncation parameter <span class="math notranslate nohighlight">\(k\)</span> in each case to get the best possible solution. What do you notice here?</p></li>
<li><p>Explain your observations by investigating what the singular vectors look like (think about the discrete Picard condition as well).</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">la</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.dpi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># parameters and grid</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># define forward operator</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="n">a</span><span class="p">))</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">toeplitz</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="c1"># ground truth and data</span>
<span class="n">u</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">.2</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">K</span><span class="nd">@u</span> <span class="o">+</span> <span class="n">delta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;u&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_12_0.png" src="_images/discrete_ip_regularization_12_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># parameters and grid</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># define forward operator</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="n">a</span><span class="p">))</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">toeplitz</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="c1"># ground truth and data</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">K</span><span class="nd">@u</span> <span class="o">+</span> <span class="n">delta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;u&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/discrete_ip_regularization_13_0.png" src="_images/discrete_ip_regularization_13_0.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="what_is.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">1. </span>What is an inverse problem</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="ip_function_spaces.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Linear inverse problems in function spaces</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tristan van Leeuwen and Christoph Brune (CC BY-NC 4.0)<br/>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>